Decision_Tree: 18 versions x 5 iterations
Version,Sensitivity(Mean),Sensitivity(StDev),Fallout(Mean),Fallout(StDev),Specificity(Mean),Specificity(StDev),Miss_Rate(Mean),Miss_Rate(StDev),Test_Error(Mean),Test_Error(StDev),AUC(Mean),AUC(StDev),Exec_Time(Mean),Exec_Time(StDev)
1,0.9339,0.0,0.1206,0.0,0.8794,0.0,0.0661,0.0,0.0954,0.0,0.9043,0.0,7.3,2.9765
2,0.9206,0.0,0.1029,0.0,0.8971,0.0,0.0794,0.0,0.0916,0.0,0.9083,0.0,5.6078,0.036
3,0.9062,0.0,0.1045,0.0,0.8955,0.0,0.0938,0.0,0.0992,0.0,0.9007,0.0,5.621,0.0508
4,0.9339,0.0,0.1206,0.0,0.8794,0.0,0.0661,0.0,0.0954,0.0,0.9043,0.0,5.5538,0.0383
5,0.9206,0.0,0.1029,0.0,0.8971,0.0,0.0794,0.0,0.0916,0.0,0.9083,0.0,5.6378,0.101
6,0.9062,0.0,0.1045,0.0,0.8955,0.0,0.0938,0.0,0.0992,0.0,0.9007,0.0,5.7506,0.0462
7,0.9339,0.0,0.1206,0.0,0.8794,0.0,0.0661,0.0,0.0954,0.0,0.9043,0.0,5.675,0.0492
8,0.9141,0.0,0.097,0.0,0.903,0.0,0.0859,0.0,0.0916,0.0,0.9083,0.0,5.776,0.0357
9,0.907,0.0,0.0977,0.0,0.9023,0.0,0.093,0.0,0.0954,0.0,0.9045,0.0,5.9352,0.0636
10,0.936,0.0,0.0949,0.0,0.9051,0.0,0.064,0.0,0.0802,0.0,0.9197,0.0,5.3666,0.0711
11,0.9084,0.0,0.084,0.0,0.916,0.0,0.0916,0.0,0.0878,0.0,0.9122,0.0,5.3944,0.0266
12,0.9008,0.0,0.0916,0.0,0.9084,0.0,0.0992,0.0,0.0954,0.0,0.9046,0.0,5.5852,0.0406
13,0.9154,0.0,0.0833,0.0,0.9167,0.0,0.0846,0.0,0.084,0.0,0.916,0.0,5.4874,0.0295
14,0.9219,0.0,0.0896,0.0,0.9104,0.0,0.0781,0.0,0.084,0.0,0.916,0.0,5.5778,0.0826
15,0.907,0.0,0.0977,0.0,0.9023,0.0,0.093,0.0,0.0954,0.0,0.9045,0.0,5.7588,0.0818
16,0.8686,0.0,0.088,0.0,0.912,0.0,0.1314,0.0,0.1107,0.0,0.8895,0.0,5.7096,0.0647
17,0.875,0.0,0.0873,0.0,0.9127,0.0,0.125,0.0,0.1069,0.0,0.8933,0.0,5.863,0.0889
18,0.8623,0.0,0.0887,0.0,0.9113,0.0,0.1377,0.0,0.1145,0.0,0.8857,0.0,5.981,0.0764
Best version of Decision_Tree is test n°10
With 3 parameters:
Impurity: gini
Max_Depth: 7
Max_Bins: 128
-
Mean and St_Dev of the whole Decision_Tree classifier metrics are as follows:
Sensitivity: Mean = 0.9095; St_Dev = 0.0219
Fallout: Mean = 0.0987; St_Dev = 0.0121
Specificity: Mean = 0.9013; St_Dev = 0.0121
Miss_Rate: Mean = 0.0905; St_Dev = 0.0219
Test_Error: Mean = 0.0952; St_Dev = 0.0089
AUC: Mean = 0.9047; St_Dev = 0.0088
Exec_Time: Mean = 5.7545; St_Dev = 0.4199
#############################
Random_Forest: 36 versions x 5 iterations
Version,Sensitivity(Mean),Sensitivity(StDev),Fallout(Mean),Fallout(StDev),Specificity(Mean),Specificity(StDev),Miss_Rate(Mean),Miss_Rate(StDev),Test_Error(Mean),Test_Error(StDev),AUC(Mean),AUC(StDev),Exec_Time(Mean),Exec_Time(StDev)
1,0.9655,0.0,0.1233,0.0,0.8767,0.0,0.0345,0.0,0.084,0.0,0.9156,0.0,9.5652,0.2568
2,0.9661,0.0,0.1111,0.0,0.8889,0.0,0.0339,0.0,0.0763,0.0,0.9233,0.0,11.177,0.2283
3,0.9739,0.0,0.1224,0.0,0.8776,0.0,0.0261,0.0,0.0802,0.0,0.9194,0.0,9.8392,0.2604
4,0.9655,0.0,0.1233,0.0,0.8767,0.0,0.0345,0.0,0.084,0.0,0.9156,0.0,11.7628,0.3207
5,0.9658,0.0,0.1172,0.0,0.8828,0.0,0.0342,0.0,0.0802,0.0,0.9195,0.0,10.5186,0.1892
6,0.9655,0.0,0.1233,0.0,0.8767,0.0,0.0345,0.0,0.084,0.0,0.9156,0.0,13.4494,0.2626
7,0.9661,0.0,0.1111,0.0,0.8889,0.0,0.0339,0.0,0.0763,0.0,0.9233,0.0,10.8324,0.2356
8,0.9583,0.0,0.1056,0.0,0.8944,0.0,0.0417,0.0,0.0763,0.0,0.9234,0.0,12.8414,0.1832
9,0.9744,0.0,0.1103,0.0,0.8897,0.0,0.0256,0.0,0.0725,0.0,0.9271,0.0,11.0712,0.2759
10,0.9661,0.0,0.1111,0.0,0.8889,0.0,0.0339,0.0,0.0763,0.0,0.9233,0.0,13.5432,0.1764
11,0.9658,0.0,0.1172,0.0,0.8828,0.0,0.0342,0.0,0.0802,0.0,0.9195,0.0,12.2474,0.1996
12,0.95,0.0,0.1127,0.0,0.8873,0.0,0.05,0.0,0.084,0.0,0.9157,0.0,15.8872,0.3369
13,0.9583,0.0,0.1056,0.0,0.8944,0.0,0.0417,0.0,0.0763,0.0,0.9234,0.0,12.1002,0.1368
14,0.9583,0.0,0.1056,0.0,0.8944,0.0,0.0417,0.0,0.0763,0.0,0.9234,0.0,14.5456,0.169
15,0.9664,0.0,0.1049,0.0,0.8951,0.0,0.0336,0.0,0.0725,0.0,0.9272,0.0,12.4716,0.1807
16,0.9667,0.0,0.0986,0.0,0.9014,0.0,0.0333,0.0,0.0687,0.0,0.931,0.0,15.5452,0.2105
17,0.958,0.0,0.1119,0.0,0.8881,0.0,0.042,0.0,0.0802,0.0,0.9195,0.0,13.6296,0.0482
18,0.9583,0.0,0.1056,0.0,0.8944,0.0,0.0417,0.0,0.0763,0.0,0.9234,0.0,17.9882,0.0545
19,0.9655,0.0,0.1233,0.0,0.8767,0.0,0.0345,0.0,0.084,0.0,0.9156,0.0,9.4882,0.1719
20,0.9658,0.0,0.1172,0.0,0.8828,0.0,0.0342,0.0,0.0802,0.0,0.9195,0.0,10.9254,0.1121
21,0.9737,0.0,0.1284,0.0,0.8716,0.0,0.0263,0.0,0.084,0.0,0.9156,0.0,9.5938,0.1216
22,0.9658,0.0,0.1172,0.0,0.8828,0.0,0.0342,0.0,0.0802,0.0,0.9195,0.0,11.6296,0.1083
23,0.9655,0.0,0.1233,0.0,0.8767,0.0,0.0345,0.0,0.084,0.0,0.9156,0.0,10.2978,0.1818
24,0.9655,0.0,0.1233,0.0,0.8767,0.0,0.0345,0.0,0.084,0.0,0.9156,0.0,13.2014,0.1612
25,0.9661,0.0,0.1111,0.0,0.8889,0.0,0.0339,0.0,0.0763,0.0,0.9233,0.0,10.7628,0.1524
26,0.9664,0.0,0.1049,0.0,0.8951,0.0,0.0336,0.0,0.0725,0.0,0.9272,0.0,12.5262,0.2063
27,0.9739,0.0,0.1224,0.0,0.8776,0.0,0.0261,0.0,0.0802,0.0,0.9194,0.0,10.9404,0.1216
28,0.9661,0.0,0.1111,0.0,0.8889,0.0,0.0339,0.0,0.0763,0.0,0.9233,0.0,13.5078,0.1867
29,0.9744,0.0,0.1103,0.0,0.8897,0.0,0.0256,0.0,0.0725,0.0,0.9271,0.0,11.9726,0.2051
30,0.9664,0.0,0.1049,0.0,0.8951,0.0,0.0336,0.0,0.0725,0.0,0.9272,0.0,15.7704,0.2414
31,0.9661,0.0,0.1111,0.0,0.8889,0.0,0.0339,0.0,0.0763,0.0,0.9233,0.0,12.058,0.1462
32,0.9664,0.0,0.1049,0.0,0.8951,0.0,0.0336,0.0,0.0725,0.0,0.9272,0.0,14.4948,0.1479
33,0.9741,0.0,0.1164,0.0,0.8836,0.0,0.0259,0.0,0.0763,0.0,0.9233,0.0,12.527,0.0909
34,0.9661,0.0,0.1111,0.0,0.8889,0.0,0.0339,0.0,0.0763,0.0,0.9233,0.0,15.213,0.1222
35,0.9664,0.0,0.1049,0.0,0.8951,0.0,0.0336,0.0,0.0725,0.0,0.9272,0.0,13.449,0.2283
36,0.9664,0.0,0.1049,0.0,0.8951,0.0,0.0336,0.0,0.0725,0.0,0.9272,0.0,18.3108,0.2426
Best version of Random_Forest is test n°16
With 4 parameters:
Impurity: gini
Max_Depth: 7
Max_Bins: 64
Num_Trees: 100
-
Mean and St_Dev of the whole Random_Forest classifier metrics are as follows:
Sensitivity: Mean = 0.9658; St_Dev = 0.0052
Fallout: Mean = 0.1131; St_Dev = 0.0075
Specificity: Mean = 0.8869; St_Dev = 0.0075
Miss_Rate: Mean = 0.0342; St_Dev = 0.0052
Test_Error: Mean = 0.0777; St_Dev = 0.0044
AUC: Mean = 0.9219; St_Dev = 0.0044
Exec_Time: Mean = 12.6579; St_Dev = 2.2312
#############################
Gradient_Boosted_Tree: 12 versions x 5 iterations
Version,Sensitivity(Mean),Sensitivity(StDev),Fallout(Mean),Fallout(StDev),Specificity(Mean),Specificity(StDev),Miss_Rate(Mean),Miss_Rate(StDev),Test_Error(Mean),Test_Error(StDev),AUC(Mean),AUC(StDev),Exec_Time(Mean),Exec_Time(StDev)
1,0.9516,0.0,0.087,0.0,0.913,0.0,0.0484,0.0,0.0687,0.0,0.9311,0.0,171.526,64.1262
2,0.944,0.0,0.0876,0.0,0.9124,0.0,0.056,0.0,0.0725,0.0,0.9273,0.0,538.4008,53.0955
3,0.9355,0.0,0.1014,0.0,0.8986,0.0,0.0645,0.0,0.084,0.0,0.9159,0.0,268.7574,30.8139
4,0.935,0.0033,0.0883,0.0003,0.9117,0.0003,0.065,0.0033,0.0771,0.0017,0.9228,0.0017,529.4526,47.5553
5,0.9219,0.0,0.0896,0.0,0.9104,0.0,0.0781,0.0,0.084,0.0,0.916,0.0,280.681,11.1394
6,0.9225,0.0,0.0827,0.0,0.9173,0.0,0.0775,0.0,0.0802,0.0,0.9198,0.0,552.6262,36.6151
7,0.9274,0.0,0.1087,0.0,0.8913,0.0,0.0726,0.0,0.0916,0.0,0.9082,0.0,341.8758,36.6582
8,0.935,0.0,0.1079,0.0,0.8921,0.0,0.065,0.0,0.0878,0.0,0.912,0.0,803.1572,46.4881
9,0.9206,0.0,0.1029,0.0,0.8971,0.0,0.0794,0.0,0.0916,0.0,0.9083,0.0,326.4048,23.0972
10,0.9207,0.0003,0.1016,0.003,0.8984,0.003,0.0793,0.0003,0.0908,0.0017,0.9091,0.0017,729.3118,69.8395
11,0.9077,0.0,0.0909,0.0,0.9091,0.0,0.0923,0.0,0.0916,0.0,0.9084,0.0,360.7744,49.4417
12,0.9077,0.0,0.0909,0.0,0.9091,0.0,0.0923,0.0,0.0916,0.0,0.9084,0.0,814.3292,49.6652
Best version of Gradient_Boosted_Tree is test n°1
With 3 parameters:
Max_Depth: 5
Max_Bins: 128
Num_Iterations: 100
-
Mean and St_Dev of the whole Gradient_Boosted_Tree classifier metrics are as follows:
Sensitivity: Mean = 0.9275; St_Dev = 0.0134
Fallout: Mean = 0.095; St_Dev = 0.0089
Specificity: Mean = 0.905; St_Dev = 0.0089
Miss_Rate: Mean = 0.0725; St_Dev = 0.0134
Test_Error: Mean = 0.0843; St_Dev = 0.0081
AUC: Mean = 0.9156; St_Dev = 0.0081
Exec_Time: Mean = 476.4414; St_Dev = 218.6184
#############################
Logistic_Regression: 54 versions x 5 iterations
Version,Sensitivity(Mean),Sensitivity(StDev),Fallout(Mean),Fallout(StDev),Specificity(Mean),Specificity(StDev),Miss_Rate(Mean),Miss_Rate(StDev),Test_Error(Mean),Test_Error(StDev),AUC(Mean),AUC(StDev),Exec_Time(Mean),Exec_Time(StDev)
1,0.9902,0.0,0.1812,0.0,0.8187,0.0,0.0098,0.0,0.1145,0.0,0.8847,0.0,41.3504,6.1235
2,0.9902,0.0,0.1812,0.0,0.8187,0.0,0.0098,0.0,0.1145,0.0,0.8847,0.0,29.543,19.1346
3,0.9902,0.0,0.1812,0.0,0.8187,0.0,0.0098,0.0,0.1145,0.0,0.8847,0.0,34.8322,18.6601
4,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,9.5994,0.4373
5,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,7.155,3.4113
6,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,3.4632,0.0567
7,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,8.6564,2.8321
8,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,9.6162,0.3065
9,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,4.7636,2.8876
10,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,3.759,0.8211
11,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,10.1528,0.4176
12,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,8.729,2.9531
13,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,3.4122,0.0739
14,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,6.5744,3.6015
15,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,9.8846,0.3936
16,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,6.67,3.5642
17,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,3.4494,0.0372
18,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,8.5966,2.8105
19,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,9.6384,0.4674
20,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,4.6574,2.6449
21,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,4.714,2.7048
22,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,9.7544,0.3356
23,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,8.6642,2.8165
24,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,3.4774,0.0402
25,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,6.5052,3.2805
26,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,9.8654,0.3625
27,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,6.3988,3.3777
28,0.9902,0.0,0.1812,0.0,0.8187,0.0,0.0098,0.0,0.1145,0.0,0.8847,0.0,31.0098,17.3642
29,0.9902,0.0,0.1812,0.0,0.8187,0.0,0.0098,0.0,0.1145,0.0,0.8847,0.0,28.5514,18.095
30,0.9902,0.0,0.1812,0.0,0.8187,0.0,0.0098,0.0,0.1145,0.0,0.8847,0.0,35.5708,19.7874
31,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,9.41,0.6417
32,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,10.0238,0.2123
33,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,4.905,2.9729
34,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,4.3148,1.9912
35,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,9.9464,0.4969
36,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,8.8078,2.9615
37,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,3.4186,0.0644
38,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,6.9598,3.274
39,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,10.0996,0.4213
40,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,5.9844,3.4835
41,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,3.5002,0.0727
42,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,9.2422,2.6649
43,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,9.8736,0.4895
44,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,4.064,1.3118
45,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,4.853,2.6388
46,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,9.834,0.3057
47,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,8.0388,2.5823
48,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,3.4914,0.0417
49,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,7.1868,3.2865
50,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,10.0962,0.3646
51,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,6.2536,3.7645
52,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,3.4854,0.1403
53,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,10.3002,0.3056
54,0.4962,0.0,0.0,0.0,0.0,0.0,0.5038,0.0,0.5038,0.0,0.5,0.0,9.9316,0.6805
Best version of Logistic_Regression is test n°29
With 4 parameters:
Max_Iter: 100
Reg_Param: 0.1
Elastic_Net_Param: 0.6
Aggregation_Depth: 2
-
Mean and St_Dev of the whole Logistic_Regression classifier metrics are as follows:
Sensitivity: Mean = 0.5511; St_Dev = 0.1567
Fallout: Mean = 0.0201; St_Dev = 0.0575
Specificity: Mean = 0.091; St_Dev = 0.2597
Miss_Rate: Mean = 0.4489; St_Dev = 0.1567
Test_Error: Mean = 0.4605; St_Dev = 0.1235
AUC: Mean = 0.5427; St_Dev = 0.122
Exec_Time: Mean = 10.0562; St_Dev = 8.82
#############################
Linear_SVC: 18 versions x 5 iterations
Version,Sensitivity(Mean),Sensitivity(StDev),Fallout(Mean),Fallout(StDev),Specificity(Mean),Specificity(StDev),Miss_Rate(Mean),Miss_Rate(StDev),Test_Error(Mean),Test_Error(StDev),AUC(Mean),AUC(StDev),Exec_Time(Mean),Exec_Time(StDev)
1,0.9863,0.0,0.3069,0.0,0.6931,0.0,0.0137,0.0,0.2252,0.0,0.7731,0.0,52.8248,31.5589
2,0.9863,0.0,0.3069,0.0,0.6931,0.0,0.0137,0.0,0.2252,0.0,0.7731,0.0,58.2114,33.7193
3,0.9863,0.0,0.3069,0.0,0.6931,0.0,0.0137,0.0,0.2252,0.0,0.7731,0.0,86.0396,33.4503
4,0.9821,0.0,0.3641,0.0,0.6359,0.0,0.0179,0.0,0.2901,0.0,0.7078,0.0,60.0664,28.2802
5,0.9821,0.0,0.3641,0.0,0.6359,0.0,0.0179,0.0,0.2901,0.0,0.7078,0.0,59.1158,36.6706
6,0.9821,0.0,0.3641,0.0,0.6359,0.0,0.0179,0.0,0.2901,0.0,0.7078,0.0,87.6732,34.7829
7,0.9875,0.0,0.2802,0.0,0.7198,0.0,0.0125,0.0,0.1985,0.0,0.8001,0.0,60.0206,26.5028
8,0.9875,0.0,0.2802,0.0,0.7198,0.0,0.0125,0.0,0.1985,0.0,0.8001,0.0,56.5956,31.4578
9,0.9875,0.0,0.2802,0.0,0.7198,0.0,0.0125,0.0,0.1985,0.0,0.8001,0.0,75.3412,31.0934
10,0.9872,0.0,0.288,0.0,0.712,0.0,0.0128,0.0,0.2061,0.0,0.7924,0.0,110.3082,41.955
11,0.9872,0.0,0.288,0.0,0.712,0.0,0.0128,0.0,0.2061,0.0,0.7924,0.0,125.6614,47.4654
12,0.9872,0.0,0.288,0.0,0.712,0.0,0.0128,0.0,0.2061,0.0,0.7924,0.0,123.2972,62.1306
13,0.9828,0.0,0.3578,0.0,0.6422,0.0,0.0172,0.0,0.2824,0.0,0.7154,0.0,114.9848,43.5537
14,0.9828,0.0,0.3578,0.0,0.6422,0.0,0.0172,0.0,0.2824,0.0,0.7154,0.0,135.6162,51.2005
15,0.9828,0.0,0.3578,0.0,0.6422,0.0,0.0172,0.0,0.2824,0.0,0.7154,0.0,135.529,24.0119
16,0.9875,0.0,0.2802,0.0,0.7198,0.0,0.0125,0.0,0.1985,0.0,0.8001,0.0,164.7968,56.1881
17,0.9875,0.0,0.2802,0.0,0.7198,0.0,0.0125,0.0,0.1985,0.0,0.8001,0.0,173.6436,47.3018
18,0.9875,0.0,0.2802,0.0,0.7198,0.0,0.0125,0.0,0.1985,0.0,0.8001,0.0,207.2524,48.6263
Best version of Linear_SVC is test n°8
With 3 parameters:
Max_Iter: 50
Reg_Param: 0.5
Aggregation_Depth: 2
-
Mean and St_Dev of the whole Linear_SVC classifier metrics are as follows:
Sensitivity: Mean = 0.9856; St_Dev = 0.0023
Fallout: Mean = 0.3129; St_Dev = 0.0362
Specificity: Mean = 0.6871; St_Dev = 0.0362
Miss_Rate: Mean = 0.0144; St_Dev = 0.0023
Test_Error: Mean = 0.2335; St_Dev = 0.0396
AUC: Mean = 0.7648; St_Dev = 0.0399
Exec_Time: Mean = 104.8321; St_Dev = 46.3001
#############################
