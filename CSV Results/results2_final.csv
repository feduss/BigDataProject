Decision_Tree MLLib: 18 versions x 1 iterations
Version,Sensitivity(Mean),Sensitivity(StDev),Fallout(Mean),Fallout(StDev),Specificity(Mean),Specificity(StDev),Miss_Rate(Mean),Miss_Rate(StDev),Test_Error(Mean),Test_Error(StDev),AUC(Mean),AUC(StDev),Exec_Time(Mean),Exec_Time(StDev)
1,0.95,0.0,0.1293,0.0,0.8707,0.0,0.05,0.0,0.0801,0.0,0.9187,0.0,2.103,0.0
2,0.9465,0.0,0.1181,0.0,0.8819,0.0,0.0535,0.0,0.0775,0.0,0.9192,0.0,1.321,0.0
3,0.9426,0.0,0.1189,0.0,0.8811,0.0,0.0574,0.0,0.0801,0.0,0.9156,0.0,1.377,0.0
4,0.954,0.0,0.1284,0.0,0.8716,0.0,0.046,0.0,0.0775,0.0,0.9223,0.0,1.35,0.0
5,0.954,0.0,0.1284,0.0,0.8716,0.0,0.046,0.0,0.0775,0.0,0.9223,0.0,1.25,0.0
6,0.9421,0.0,0.131,0.0,0.869,0.0,0.0579,0.0,0.0853,0.0,0.9115,0.0,1.458,0.0
7,0.9383,0.0,0.1319,0.0,0.8681,0.0,0.0617,0.0,0.0879,0.0,0.908,0.0,1.33,0.0
8,0.9347,0.0,0.1268,0.0,0.8732,0.0,0.0653,0.0,0.0879,0.0,0.9064,0.0,1.58,0.0
9,0.9383,0.0,0.1319,0.0,0.8681,0.0,0.0617,0.0,0.0879,0.0,0.908,0.0,2.053,0.0
10,0.9306,0.0,0.1338,0.0,0.8662,0.0,0.0694,0.0,0.093,0.0,0.9008,0.0,1.437,0.0
11,0.9458,0.0,0.1361,0.0,0.8639,0.0,0.0542,0.0,0.0853,0.0,0.9131,0.0,1.561,0.0
12,0.9456,0.0,0.1419,0.0,0.8581,0.0,0.0544,0.0,0.0879,0.0,0.9111,0.0,1.924,0.0
13,0.9124,0.0,0.1324,0.0,0.8676,0.0,0.0876,0.0,0.1034,0.0,0.885,0.0,1.684,0.0
14,0.9333,0.0,0.1565,0.0,0.8435,0.0,0.0667,0.0,0.1008,0.0,0.8963,0.0,1.818,0.0
15,0.9339,0.0,0.1448,0.0,0.8552,0.0,0.0661,0.0,0.0956,0.0,0.9003,0.0,1.917,0.0
16,0.8992,0.0,0.1727,0.0,0.8273,0.0,0.1008,0.0,0.1266,0.0,0.8621,0.0,1.729,0.0
17,0.9333,0.0,0.1565,0.0,0.8435,0.0,0.0667,0.0,0.1008,0.0,0.8963,0.0,1.556,0.0
18,0.9344,0.0,0.1329,0.0,0.8671,0.0,0.0656,0.0,0.0904,0.0,0.9044,0.0,1.735,0.0
Best version of Decision_Tree MLLib is test n°5
With 3 parameters:
Impurity: gini
Max_Depth: 6
Max_Bins: 32
-
Mean and St_Dev of the whole Decision_Tree MLLib classifier metrics are as follows:
Sensitivity: Mean = 0.9372; St_Dev = 0.0137
Fallout: Mean = 0.1362; St_Dev = 0.0138
Specificity: Mean = 0.8638; St_Dev = 0.0138
Miss_Rate: Mean = 0.0628; St_Dev = 0.0137
Test_Error: Mean = 0.0903; St_Dev = 0.0122
AUC: Mean = 0.9056; St_Dev = 0.0147
Exec_Time: Mean = 1.6213; St_Dev = 0.2636
#############################
Random_Forest MLLib: 36 versions x 1 iterations
Version,Sensitivity(Mean),Sensitivity(StDev),Fallout(Mean),Fallout(StDev),Specificity(Mean),Specificity(StDev),Miss_Rate(Mean),Miss_Rate(StDev),Test_Error(Mean),Test_Error(StDev),AUC(Mean),AUC(StDev),Exec_Time(Mean),Exec_Time(StDev)
1,0.9828,0.0,0.1226,0.0,0.8774,0.0,0.0172,0.0,0.0594,0.0,0.9473,0.0,3.129,0.0
2,0.9828,0.0,0.1169,0.0,0.8831,0.0,0.0172,0.0,0.0568,0.0,0.9493,0.0,4.4,0.0
3,0.9828,0.0,0.1169,0.0,0.8831,0.0,0.0172,0.0,0.0568,0.0,0.9493,0.0,3.492,0.0
4,0.9827,0.0,0.1282,0.0,0.8718,0.0,0.0173,0.0,0.062,0.0,0.9452,0.0,5.92,0.0
5,0.9784,0.0,0.129,0.0,0.871,0.0,0.0216,0.0,0.0646,0.0,0.9417,0.0,5.166,0.0
6,0.9786,0.0,0.1176,0.0,0.8824,0.0,0.0214,0.0,0.0594,0.0,0.9457,0.0,8.244,0.0
7,0.9785,0.0,0.1234,0.0,0.8766,0.0,0.0215,0.0,0.062,0.0,0.9437,0.0,3.77,0.0
8,0.9828,0.0,0.1169,0.0,0.8831,0.0,0.0172,0.0,0.0568,0.0,0.9493,0.0,5.311,0.0
9,0.9828,0.0,0.1169,0.0,0.8831,0.0,0.0172,0.0,0.0568,0.0,0.9493,0.0,4.114,0.0
10,0.9784,0.0,0.1346,0.0,0.8654,0.0,0.0216,0.0,0.0672,0.0,0.9396,0.0,6.529,0.0
11,0.9785,0.0,0.1234,0.0,0.8766,0.0,0.0215,0.0,0.062,0.0,0.9437,0.0,5.522,0.0
12,0.9784,0.0,0.129,0.0,0.871,0.0,0.0216,0.0,0.0646,0.0,0.9417,0.0,9.14,0.0
13,0.9829,0.0,0.1111,0.0,0.8889,0.0,0.0171,0.0,0.0543,0.0,0.9513,0.0,4.235,0.0
14,0.9746,0.0,0.1126,0.0,0.8874,0.0,0.0254,0.0,0.0594,0.0,0.9442,0.0,5.642,0.0
15,0.9785,0.0,0.1234,0.0,0.8766,0.0,0.0215,0.0,0.062,0.0,0.9437,0.0,4.175,0.0
16,0.9787,0.0,0.1118,0.0,0.8882,0.0,0.0213,0.0,0.0568,0.0,0.9477,0.0,6.949,0.0
17,0.9785,0.0,0.1234,0.0,0.8766,0.0,0.0215,0.0,0.062,0.0,0.9437,0.0,5.619,0.0
18,0.9786,0.0,0.1176,0.0,0.8824,0.0,0.0214,0.0,0.0594,0.0,0.9457,0.0,9.874,0.0
19,0.9825,0.0,0.1392,0.0,0.8608,0.0,0.0175,0.0,0.0672,0.0,0.9412,0.0,2.76,0.0
20,0.9827,0.0,0.1282,0.0,0.8718,0.0,0.0173,0.0,0.062,0.0,0.9452,0.0,4.485,0.0
21,0.9826,0.0,0.1338,0.0,0.8662,0.0,0.0174,0.0,0.0646,0.0,0.9432,0.0,3.688,0.0
22,0.9827,0.0,0.1282,0.0,0.8718,0.0,0.0173,0.0,0.062,0.0,0.9452,0.0,5.259,0.0
23,0.9826,0.0,0.1338,0.0,0.8662,0.0,0.0174,0.0,0.0646,0.0,0.9432,0.0,4.631,0.0
24,0.9827,0.0,0.1282,0.0,0.8718,0.0,0.0173,0.0,0.062,0.0,0.9452,0.0,7.635,0.0
25,0.9871,0.0,0.1161,0.0,0.8839,0.0,0.0129,0.0,0.0543,0.0,0.9528,0.0,3.732,0.0
26,0.9828,0.0,0.1226,0.0,0.8774,0.0,0.0172,0.0,0.0594,0.0,0.9473,0.0,5.524,0.0
27,0.9828,0.0,0.1226,0.0,0.8774,0.0,0.0172,0.0,0.0594,0.0,0.9473,0.0,4.136,0.0
28,0.9827,0.0,0.1282,0.0,0.8718,0.0,0.0173,0.0,0.062,0.0,0.9452,0.0,6.515,0.0
29,0.9784,0.0,0.129,0.0,0.871,0.0,0.0216,0.0,0.0646,0.0,0.9417,0.0,5.337,0.0
30,0.9828,0.0,0.1226,0.0,0.8774,0.0,0.0172,0.0,0.0594,0.0,0.9473,0.0,9.279,0.0
31,0.9827,0.0,0.1282,0.0,0.8718,0.0,0.0173,0.0,0.062,0.0,0.9452,0.0,4.376,0.0
32,0.983,0.0,0.1053,0.0,0.8947,0.0,0.017,0.0,0.0517,0.0,0.9533,0.0,6.278,0.0
33,0.9828,0.0,0.1169,0.0,0.8831,0.0,0.0172,0.0,0.0568,0.0,0.9493,0.0,5.113,0.0
34,0.9828,0.0,0.1226,0.0,0.8774,0.0,0.0172,0.0,0.0594,0.0,0.9473,0.0,7.961,0.0
35,0.9784,0.0,0.1346,0.0,0.8654,0.0,0.0216,0.0,0.0672,0.0,0.9396,0.0,6.12,0.0
36,0.9828,0.0,0.1169,0.0,0.8831,0.0,0.0172,0.0,0.0568,0.0,0.9493,0.0,11.66,0.0
Best version of Random_Forest MLLib is test n°32
With 4 parameters:
Impurity: entropy
Max_Depth: 7
Max_Bins: 32
Num_Trees: 100
-
Mean and St_Dev of the whole Random_Forest MLLib classifier metrics are as follows:
Sensitivity: Mean = 0.9812; St_Dev = 0.0025
Fallout: Mean = 0.1231; St_Dev = 0.0077
Specificity: Mean = 0.8769; St_Dev = 0.0077
Miss_Rate: Mean = 0.0188; St_Dev = 0.0025
Test_Error: Mean = 0.0605; St_Dev = 0.0038
AUC: Mean = 0.9459; St_Dev = 0.0034
Exec_Time: Mean = 5.7144; St_Dev = 2.0342
#############################
Gradient Boosted Tree: 36 versions x 1 iterations
Version,Sensitivity(Mean),Sensitivity(StDev),Fallout(Mean),Fallout(StDev),Specificity(Mean),Specificity(StDev),Miss_Rate(Mean),Miss_Rate(StDev),Test_Error(Mean),Test_Error(StDev),AUC(Mean),AUC(StDev),Exec_Time(Mean),Exec_Time(StDev)
1,0.9472,0.0,0.0993,0.0,0.9007,0.0,0.0528,0.0,0.0698,0.0,0.9252,0.0,36.377,0.0
2,0.9469,0.0,0.1056,0.0,0.8944,0.0,0.0531,0.0,0.0724,0.0,0.9232,0.0,84.341,0.0
3,0.9583,0.0,0.1156,0.0,0.8844,0.0,0.0417,0.0,0.0698,0.0,0.9299,0.0,41.898,0.0
4,0.9544,0.0,0.1164,0.0,0.8836,0.0,0.0456,0.0,0.0724,0.0,0.9263,0.0,89.872,0.0
5,0.9545,0.0,0.1103,0.0,0.8897,0.0,0.0455,0.0,0.0698,0.0,0.9283,0.0,46.204,0.0
6,0.9467,0.0,0.1119,0.0,0.8881,0.0,0.0533,0.0,0.0749,0.0,0.9212,0.0,93.226,0.0
7,0.9274,0.0,0.1223,0.0,0.8777,0.0,0.0726,0.0,0.0904,0.0,0.9013,0.0,54.451,0.0
8,0.928,0.0,0.1095,0.0,0.8905,0.0,0.072,0.0,0.0853,0.0,0.9053,0.0,122.08,0.0
9,0.9426,0.0,0.1189,0.0,0.8811,0.0,0.0574,0.0,0.0801,0.0,0.9156,0.0,50.131,0.0
10,0.9504,0.0,0.1172,0.0,0.8828,0.0,0.0496,0.0,0.0749,0.0,0.9227,0.0,134.076,0.0
11,0.9431,0.0,0.1064,0.0,0.8936,0.0,0.0569,0.0,0.0749,0.0,0.9196,0.0,61.761,0.0
12,0.9508,0.0,0.1049,0.0,0.8951,0.0,0.0492,0.0,0.0698,0.0,0.9268,0.0,142.179,0.0
13,0.9393,0.0,0.1071,0.0,0.8929,0.0,0.0607,0.0,0.0775,0.0,0.9161,0.0,34.729,0.0
14,0.939,0.0,0.1135,0.0,0.8865,0.0,0.061,0.0,0.0801,0.0,0.914,0.0,77.603,0.0
15,0.9472,0.0,0.0993,0.0,0.9007,0.0,0.0528,0.0,0.0698,0.0,0.9252,0.0,34.641,0.0
16,0.9472,0.0,0.0993,0.0,0.9007,0.0,0.0528,0.0,0.0698,0.0,0.9252,0.0,90.398,0.0
17,0.9398,0.0,0.0942,0.0,0.9058,0.0,0.0602,0.0,0.0724,0.0,0.9201,0.0,42.624,0.0
18,0.9395,0.0,0.1007,0.0,0.8993,0.0,0.0605,0.0,0.0749,0.0,0.9181,0.0,96.894,0.0
19,0.9426,0.0,0.1189,0.0,0.8811,0.0,0.0574,0.0,0.0801,0.0,0.9156,0.0,52.313,0.0
20,0.9426,0.0,0.1189,0.0,0.8811,0.0,0.0574,0.0,0.0801,0.0,0.9156,0.0,125.726,0.0
21,0.9463,0.0,0.1241,0.0,0.8759,0.0,0.0537,0.0,0.0801,0.0,0.9171,0.0,52.03,0.0
22,0.9463,0.0,0.1241,0.0,0.8759,0.0,0.0537,0.0,0.0801,0.0,0.9171,0.0,117.329,0.0
23,0.9506,0.0,0.1111,0.0,0.8889,0.0,0.0494,0.0,0.0724,0.0,0.9248,0.0,51.46,0.0
24,0.9465,0.0,0.1181,0.0,0.8819,0.0,0.0535,0.0,0.0775,0.0,0.9192,0.0,125.439,0.0
25,0.9431,0.0,0.1064,0.0,0.8936,0.0,0.0569,0.0,0.0749,0.0,0.9196,0.0,30.736,0.0
26,0.9431,0.0,0.1064,0.0,0.8936,0.0,0.0569,0.0,0.0749,0.0,0.9196,0.0,69.187,0.0
27,0.9435,0.0,0.0935,0.0,0.9065,0.0,0.0565,0.0,0.0698,0.0,0.9237,0.0,31.847,0.0
28,0.9474,0.0,0.0929,0.0,0.9071,0.0,0.0526,0.0,0.0672,0.0,0.9273,0.0,71.835,0.0
29,0.9246,0.0,0.1037,0.0,0.8963,0.0,0.0754,0.0,0.0853,0.0,0.9038,0.0,34.604,0.0
30,0.9355,0.0,0.1079,0.0,0.8921,0.0,0.0645,0.0,0.0801,0.0,0.9125,0.0,77.475,0.0
31,0.9317,0.0,0.1087,0.0,0.8913,0.0,0.0683,0.0,0.0827,0.0,0.9089,0.0,42.488,0.0
32,0.9352,0.0,0.1143,0.0,0.8857,0.0,0.0648,0.0,0.0827,0.0,0.9105,0.0,104.38,0.0
33,0.9458,0.0,0.1361,0.0,0.8639,0.0,0.0542,0.0,0.0853,0.0,0.9131,0.0,43.835,0.0
34,0.9538,0.0,0.1342,0.0,0.8658,0.0,0.0462,0.0,0.0801,0.0,0.9202,0.0,107.545,0.0
35,0.9506,0.0,0.1111,0.0,0.8889,0.0,0.0494,0.0,0.0724,0.0,0.9248,0.0,50.338,0.0
36,0.9388,0.0,0.1197,0.0,0.8803,0.0,0.0612,0.0,0.0827,0.0,0.912,0.0,119.987,0.0
Best version of Gradient Boosted Tree is test n°28
With 4 parameters:
Loss: leastAbsoluteError
Max_Depth: 3
Max_Bins: 64
Num_Iterations: 50
-
Mean and St_Dev of the whole Gradient Boosted Tree classifier metrics are as follows:
Sensitivity: Mean = 0.9436; St_Dev = 0.0077
Fallout: Mean = 0.1112; St_Dev = 0.0103
Specificity: Mean = 0.8888; St_Dev = 0.0103
Miss_Rate: Mean = 0.0564; St_Dev = 0.0077
Test_Error: Mean = 0.0766; St_Dev = 0.0057
AUC: Mean = 0.9186; St_Dev = 0.007
Exec_Time: Mean = 73.39; St_Dev = 34.2315
#############################
Logistic Regression: 54 versions x 1 iterations
Version,Sensitivity(Mean),Sensitivity(StDev),Fallout(Mean),Fallout(StDev),Specificity(Mean),Specificity(StDev),Miss_Rate(Mean),Miss_Rate(StDev),Test_Error(Mean),Test_Error(StDev),AUC(Mean),AUC(StDev),Exec_Time(Mean),Exec_Time(StDev)
1,1.0,0.0,0.1765,0.0,0.8235,0.0,0.0,0.0,0.0775,0.0,0.9393,0.0,2.052,0.0
2,1.0,0.0,0.1667,0.0,0.8333,0.0,0.0,0.0,0.0724,0.0,0.9433,0.0,2.014,0.0
3,0.9913,0.0,0.1266,0.0,0.8734,0.0,0.0087,0.0,0.0568,0.0,0.9524,0.0,1.972,0.0
4,1.0,0.0,0.1765,0.0,0.8235,0.0,0.0,0.0,0.0775,0.0,0.9393,0.0,1.853,0.0
5,1.0,0.0,0.1667,0.0,0.8333,0.0,0.0,0.0,0.0724,0.0,0.9433,0.0,1.836,0.0
6,0.9913,0.0,0.1266,0.0,0.8734,0.0,0.0087,0.0,0.0568,0.0,0.9524,0.0,1.923,0.0
7,1.0,0.0,0.1765,0.0,0.8235,0.0,0.0,0.0,0.0775,0.0,0.9393,0.0,1.948,0.0
8,1.0,0.0,0.1667,0.0,0.8333,0.0,0.0,0.0,0.0724,0.0,0.9433,0.0,1.932,0.0
9,0.9913,0.0,0.1266,0.0,0.8734,0.0,0.0087,0.0,0.0568,0.0,0.9524,0.0,1.903,0.0
10,1.0,0.0,0.1765,0.0,0.8235,0.0,0.0,0.0,0.0775,0.0,0.9393,0.0,1.892,0.0
11,1.0,0.0,0.1667,0.0,0.8333,0.0,0.0,0.0,0.0724,0.0,0.9433,0.0,1.928,0.0
12,0.9913,0.0,0.1266,0.0,0.8734,0.0,0.0087,0.0,0.0568,0.0,0.9524,0.0,2.091,0.0
13,1.0,0.0,0.1765,0.0,0.8235,0.0,0.0,0.0,0.0775,0.0,0.9393,0.0,1.978,0.0
14,1.0,0.0,0.1667,0.0,0.8333,0.0,0.0,0.0,0.0724,0.0,0.9433,0.0,1.967,0.0
15,0.9913,0.0,0.1266,0.0,0.8734,0.0,0.0087,0.0,0.0568,0.0,0.9524,0.0,1.971,0.0
16,1.0,0.0,0.1765,0.0,0.8235,0.0,0.0,0.0,0.0775,0.0,0.9393,0.0,1.797,0.0
17,1.0,0.0,0.1667,0.0,0.8333,0.0,0.0,0.0,0.0724,0.0,0.9433,0.0,1.894,0.0
18,0.9913,0.0,0.1266,0.0,0.8734,0.0,0.0087,0.0,0.0568,0.0,0.9524,0.0,2.097,0.0
19,1.0,0.0,0.1765,0.0,0.8235,0.0,0.0,0.0,0.0775,0.0,0.9393,0.0,1.836,0.0
20,1.0,0.0,0.1667,0.0,0.8333,0.0,0.0,0.0,0.0724,0.0,0.9433,0.0,1.911,0.0
21,0.9913,0.0,0.1266,0.0,0.8734,0.0,0.0087,0.0,0.0568,0.0,0.9524,0.0,2.022,0.0
22,1.0,0.0,0.1765,0.0,0.8235,0.0,0.0,0.0,0.0775,0.0,0.9393,0.0,1.875,0.0
23,1.0,0.0,0.1667,0.0,0.8333,0.0,0.0,0.0,0.0724,0.0,0.9433,0.0,1.878,0.0
24,0.9913,0.0,0.1266,0.0,0.8734,0.0,0.0087,0.0,0.0568,0.0,0.9524,0.0,1.984,0.0
25,1.0,0.0,0.1765,0.0,0.8235,0.0,0.0,0.0,0.0775,0.0,0.9393,0.0,1.868,0.0
26,1.0,0.0,0.1667,0.0,0.8333,0.0,0.0,0.0,0.0724,0.0,0.9433,0.0,1.952,0.0
27,0.9913,0.0,0.1266,0.0,0.8734,0.0,0.0087,0.0,0.0568,0.0,0.9524,0.0,2.005,0.0
28,1.0,0.0,0.1765,0.0,0.8235,0.0,0.0,0.0,0.0775,0.0,0.9393,0.0,1.878,0.0
29,1.0,0.0,0.1667,0.0,0.8333,0.0,0.0,0.0,0.0724,0.0,0.9433,0.0,1.999,0.0
30,0.9913,0.0,0.1266,0.0,0.8734,0.0,0.0087,0.0,0.0568,0.0,0.9524,0.0,1.978,0.0
31,1.0,0.0,0.1765,0.0,0.8235,0.0,0.0,0.0,0.0775,0.0,0.9393,0.0,1.915,0.0
32,1.0,0.0,0.1667,0.0,0.8333,0.0,0.0,0.0,0.0724,0.0,0.9433,0.0,1.817,0.0
33,0.9913,0.0,0.1266,0.0,0.8734,0.0,0.0087,0.0,0.0568,0.0,0.9524,0.0,1.907,0.0
34,1.0,0.0,0.1765,0.0,0.8235,0.0,0.0,0.0,0.0775,0.0,0.9393,0.0,1.767,0.0
35,1.0,0.0,0.1667,0.0,0.8333,0.0,0.0,0.0,0.0724,0.0,0.9433,0.0,1.925,0.0
36,0.9913,0.0,0.1266,0.0,0.8734,0.0,0.0087,0.0,0.0568,0.0,0.9524,0.0,1.892,0.0
37,1.0,0.0,0.1765,0.0,0.8235,0.0,0.0,0.0,0.0775,0.0,0.9393,0.0,2.038,0.0
38,1.0,0.0,0.1667,0.0,0.8333,0.0,0.0,0.0,0.0724,0.0,0.9433,0.0,1.976,0.0
39,0.9913,0.0,0.1266,0.0,0.8734,0.0,0.0087,0.0,0.0568,0.0,0.9524,0.0,2.018,0.0
40,1.0,0.0,0.1765,0.0,0.8235,0.0,0.0,0.0,0.0775,0.0,0.9393,0.0,1.842,0.0
41,1.0,0.0,0.1667,0.0,0.8333,0.0,0.0,0.0,0.0724,0.0,0.9433,0.0,1.918,0.0
42,0.9913,0.0,0.1266,0.0,0.8734,0.0,0.0087,0.0,0.0568,0.0,0.9524,0.0,2.052,0.0
43,1.0,0.0,0.1765,0.0,0.8235,0.0,0.0,0.0,0.0775,0.0,0.9393,0.0,1.805,0.0
44,1.0,0.0,0.1667,0.0,0.8333,0.0,0.0,0.0,0.0724,0.0,0.9433,0.0,2.044,0.0
45,0.9913,0.0,0.1266,0.0,0.8734,0.0,0.0087,0.0,0.0568,0.0,0.9524,0.0,1.878,0.0
46,1.0,0.0,0.1765,0.0,0.8235,0.0,0.0,0.0,0.0775,0.0,0.9393,0.0,1.934,0.0
47,1.0,0.0,0.1667,0.0,0.8333,0.0,0.0,0.0,0.0724,0.0,0.9433,0.0,1.974,0.0
48,0.9913,0.0,0.1266,0.0,0.8734,0.0,0.0087,0.0,0.0568,0.0,0.9524,0.0,1.988,0.0
49,1.0,0.0,0.1765,0.0,0.8235,0.0,0.0,0.0,0.0775,0.0,0.9393,0.0,1.825,0.0
50,1.0,0.0,0.1667,0.0,0.8333,0.0,0.0,0.0,0.0724,0.0,0.9433,0.0,2.117,0.0
51,0.9913,0.0,0.1266,0.0,0.8734,0.0,0.0087,0.0,0.0568,0.0,0.9524,0.0,2.059,0.0
52,1.0,0.0,0.1765,0.0,0.8235,0.0,0.0,0.0,0.0775,0.0,0.9393,0.0,1.814,0.0
53,1.0,0.0,0.1667,0.0,0.8333,0.0,0.0,0.0,0.0724,0.0,0.9433,0.0,2.011,0.0
54,0.9913,0.0,0.1266,0.0,0.8734,0.0,0.0087,0.0,0.0568,0.0,0.9524,0.0,2.011,0.0
Best version of Logistic Regression is test n°45
With 4 parameters:
Max_Iter: 100
Reg_Param: 0.3
Elastic_Net_Param: 1.2
Aggregation_Depth: 3
-
Mean and St_Dev of the whole Logistic Regression classifier metrics are as follows:
Sensitivity: Mean = 0.9971; St_Dev = 0.0041
Fallout: Mean = 0.1566; St_Dev = 0.0218
Specificity: Mean = 0.8434; St_Dev = 0.0218
Miss_Rate: Mean = 0.0029; St_Dev = 0.0041
Test_Error: Mean = 0.0689; St_Dev = 0.0089
AUC: Mean = 0.945; St_Dev = 0.0055
Exec_Time: Mean = 1.94; St_Dev = 0.0837
#############################
LinearSVC: 18 versions x 1 iterations
Version,Sensitivity(Mean),Sensitivity(StDev),Fallout(Mean),Fallout(StDev),Specificity(Mean),Specificity(StDev),Miss_Rate(Mean),Miss_Rate(StDev),Test_Error(Mean),Test_Error(StDev),AUC(Mean),AUC(StDev),Exec_Time(Mean),Exec_Time(StDev)
1,1.0,0.0,0.1716,0.0,0.8284,0.0,0.0,0.0,0.0749,0.0,0.9413,0.0,24.894,0.0
2,1.0,0.0,0.1716,0.0,0.8284,0.0,0.0,0.0,0.0749,0.0,0.9413,0.0,23.404,0.0
3,1.0,0.0,0.1716,0.0,0.8284,0.0,0.0,0.0,0.0749,0.0,0.9413,0.0,23.603,0.0
4,1.0,0.0,0.1716,0.0,0.8284,0.0,0.0,0.0,0.0749,0.0,0.9413,0.0,23.521,0.0
5,1.0,0.0,0.1716,0.0,0.8284,0.0,0.0,0.0,0.0749,0.0,0.9413,0.0,23.475,0.0
6,1.0,0.0,0.1716,0.0,0.8284,0.0,0.0,0.0,0.0749,0.0,0.9413,0.0,23.364,0.0
7,1.0,0.0,0.1716,0.0,0.8284,0.0,0.0,0.0,0.0749,0.0,0.9413,0.0,23.934,0.0
8,1.0,0.0,0.1716,0.0,0.8284,0.0,0.0,0.0,0.0749,0.0,0.9413,0.0,23.587,0.0
9,1.0,0.0,0.1716,0.0,0.8284,0.0,0.0,0.0,0.0749,0.0,0.9413,0.0,23.407,0.0
10,1.0,0.0,0.1716,0.0,0.8284,0.0,0.0,0.0,0.0749,0.0,0.9413,0.0,23.493,0.0
11,1.0,0.0,0.1716,0.0,0.8284,0.0,0.0,0.0,0.0749,0.0,0.9413,0.0,23.497,0.0
12,1.0,0.0,0.1716,0.0,0.8284,0.0,0.0,0.0,0.0749,0.0,0.9413,0.0,23.231,0.0
13,1.0,0.0,0.1716,0.0,0.8284,0.0,0.0,0.0,0.0749,0.0,0.9413,0.0,23.487,0.0
14,1.0,0.0,0.1716,0.0,0.8284,0.0,0.0,0.0,0.0749,0.0,0.9413,0.0,23.416,0.0
15,1.0,0.0,0.1716,0.0,0.8284,0.0,0.0,0.0,0.0749,0.0,0.9413,0.0,23.647,0.0
16,1.0,0.0,0.1716,0.0,0.8284,0.0,0.0,0.0,0.0749,0.0,0.9413,0.0,23.495,0.0
17,1.0,0.0,0.1716,0.0,0.8284,0.0,0.0,0.0,0.0749,0.0,0.9413,0.0,23.48,0.0
18,1.0,0.0,0.1716,0.0,0.8284,0.0,0.0,0.0,0.0749,0.0,0.9413,0.0,23.691,0.0
Best version of LinearSVC is test n°12
With 3 parameters:
Max_Iter: 100
Reg_Param: 0.1
Aggregation_Depth: 3
-
Mean and St_Dev of the whole LinearSVC classifier metrics are as follows:
Sensitivity: Mean = 1.0; St_Dev = 0.0
Fallout: Mean = 0.1716; St_Dev = 0.0
Specificity: Mean = 0.8284; St_Dev = 0.0
Miss_Rate: Mean = 0.0; St_Dev = 0.0
Test_Error: Mean = 0.0749; St_Dev = 0.0
AUC: Mean = 0.9413; St_Dev = 0.0
Exec_Time: Mean = 23.5903; St_Dev = 0.358
#############################
